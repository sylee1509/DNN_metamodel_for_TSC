{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb66d71-83d6-47ce-a8f6-b2641636fe28",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fd537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a70057",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data/data_total.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feade057",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycols = [\n",
    "    x+str(i) for i in range(5) for x in ['speed', 'stop', 'timeloss', 'travel', 'wait']\n",
    "]\n",
    "\n",
    "ycol = [\n",
    "    df.columns[df.columns.str.contains('wait')],\n",
    "    df.columns[df.columns.str.contains('timeloss')],\n",
    "    df.columns[df.columns.str.contains('travel')],\n",
    "    df.columns[df.columns.str.contains('speed')],\n",
    "    df.columns[df.columns.str.contains('stop')],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\n",
    "    df[c].mean(1) for c in ycol\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07406a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv('preprocessed/preprocessed_p.csv', index_col=0)\n",
    "q = pd.read_csv('preprocessed/preprocessed_q.csv', index_col=0)\n",
    "var = pd.read_csv('preprocessed/preprocessed_var.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d932972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d561dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca133eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a255276",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41251d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([var, p, q], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:,:3] /= 300\n",
    "y[:, 3] = (y[:, 3]-3)/6\n",
    "y[:, 4] /= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38b81e-6363-4948-a8f2-d8cc9a536ff2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a32c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MMoE_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X.shape[1]\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    mmoe_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "        g_in = g_layer(i_)\n",
    "        g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "        g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "        \n",
    "        g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "        \n",
    "        mmoe_outs.append(g_mul_out)\n",
    "        \n",
    "    task_outs = []\n",
    "    for mmoe_out in mmoe_outs:\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(mmoe_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def build_layer(in_dim, h_dim, out_dim):\n",
    "    i_ = Input((in_dim, ))\n",
    "    h = i_\n",
    "    for d in h_dim:\n",
    "       h = Dense(d, activation='swish')(h)\n",
    "    \n",
    "    o = Dense(out_dim)(h)\n",
    "    model = tf.keras.models.Model(i_, o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b91df6-eec0-451c-a440-c40b50e84caf",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/test_networks.csv', 'r', newline='') as myfile:\n",
    "     wr = csv.reader(myfile, quoting=csv.QUOTE_ALL)\n",
    "     test_data = list(wr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384c9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "val_id = list(tqdm(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de1d7b-2af8-4f45-bb49-e1edfea4f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = X[~strat.isin(val_id)]\n",
    "tr_y = y[~strat.isin(val_id)]\n",
    "\n",
    "val_X = X[strat.isin(val_id)]\n",
    "val_y = y[strat.isin(val_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8890b18-9bea-4781-81b1-80d5276907e6",
   "metadata": {},
   "source": [
    "## Sample Efficiency of Multi-output MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733badc8-af2f-4304-9fc3-40289a6b500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incremental_balanced_sample(tr_X, tr_y, samples_per_network, num_networks=600, network_size=5000):\n",
    "    samples = []\n",
    "    targets = []\n",
    "    for i in range(num_networks):\n",
    "        start = i * network_size\n",
    "        end = start + samples_per_network\n",
    "        samples.append(tr_X.iloc[start:end])\n",
    "        targets.append(tr_y[start:end])\n",
    "    X = pd.concat(samples).reset_index(drop=True)\n",
    "    y = np.concatenate(targets)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad68c9a-1d40-450e-b8a4-d94d648f3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_numbers_per_network = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee527e6-d370-41de-b431-d4b5b39b1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d75a9e-e7d1-4291-8e26-92cfd9d2f091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "for sample_number in sample_numbers_per_network:    \n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "    ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "    \n",
    "    model = get_MMoE_model()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "    X_k, y_k = get_incremental_balanced_sample(tr_X, tr_y, sample_number)\n",
    "    \n",
    "    history = model.fit(X_k, y_k,\n",
    "             epochs=1500,\n",
    "             batch_size=1024,\n",
    "             validation_split=0.15,\n",
    "             callbacks=[es, ld],\n",
    "             shuffle=True,\n",
    "             )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f'Elapsed time is {end_time - start_time} seconds')\n",
    "    \n",
    "    model.save(f\"model_MMoE_{sample_number}_samples_per_network\")\n",
    "    \n",
    "    with open(f'model_MMoE_{sample_number}_samples_per_network/historyDict', 'wb') as f:\n",
    "        pickle.dump(history.history, f)        \n",
    "\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62540d-4d69-4f9f-aa35-8ba1ca17b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f75ed35d-5561-4f2f-8c5e-693a59877936",
   "metadata": {},
   "source": [
    "# Seaborn settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbdb34-1d3d-46fc-a09e-54c96d13f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f54e21-1dd3-4bf7-b16d-c6ea93945728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff68c1-bcf7-4e5c-b788-8ecec7d09b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99938818-0310-44af-af7f-b1b97f717c5b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe206cbb-17a0-4843-8e32-c7ad674360cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMoE_models = {\n",
    "    sample_number: tf.keras.models.load_model(f'models/model_MMoE_{sample_number}_samples_per_network') \n",
    "    for sample_number in [10, 20, 50, 100, 200, 500, 1000, 2000, 5000]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e8673-808e-40be-98b9-c2db9fcca599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/test_networks.csv', 'r', newline='') as myfile:\n",
    "     wr = csv.reader(myfile, quoting=csv.QUOTE_ALL)\n",
    "     test_data = list(wr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e64790-54b4-4485-812a-8c62f12c5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "val_id = list(tqdm(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130aaed-eef3-468a-ac4f-f6be1e5055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_results = []\n",
    "\n",
    "for model_name, model in MMoE_models.items():\n",
    "    num_tasks = 5\n",
    "    \n",
    "    test_X = val_X\n",
    "    test_y = val_y\n",
    "    \n",
    "    pred = model.predict(test_X)\n",
    "    trues = test_y\n",
    "    \n",
    "    # score writer\n",
    "    tmp_scr = [model_name]\n",
    "    tmp_scr.append((np.abs(pred - trues) / trues).mean() * 100)\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        s_ = ((np.abs(pred[:,i] - trues[:,i])*300) / (trues[:,i]*300)).mean() * 100\n",
    "        tmp_scr.append(s_)\n",
    "\n",
    "    prediction_results.append(tmp_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d4d5a-da25-4947-8fc2-f8cf848c9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(prediction_results, columns = ['sample number', 'total', 'wait', 'timeloss', 'travel', 'speed', 'stop'])\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960ae7b-22d8-4eaf-9931-a287360b6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_time = pd.read_csv('training_time.csv')\n",
    "df_merged = pd.merge(df_prediction, df_training_time, on='sample number')\n",
    "df_merged.columns = ['sample number', 'average', 'waiting time', 'time loss', 'travel time', 'speed', 'waiting count', 'training time']\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acccff-5757-4202-a661-8e2a9d0f4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794b8d2-7e55-4db6-a3f7-820c54fe7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df_merged['sample number']\n",
    "y_metrics = ['average', 'waiting time', 'time loss', 'travel time', 'speed', 'waiting count']\n",
    "training_time = df_merged['training time']\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# log scale\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# left y-axis : performance measures\n",
    "lines_1 = []\n",
    "labels_1 = []\n",
    "\n",
    "for col in y_metrics:\n",
    "    line, = ax1.plot(x, df_merged[col], marker='o', label=col)\n",
    "    lines_1.append(line)\n",
    "    labels_1.append(col)\n",
    "\n",
    "ax1.set_xlabel('Sample Number (log scale)')\n",
    "ax1.set_ylabel('MAPE (%)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# right y-axis: training time\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(x, training_time, color='black', linestyle='--', marker='x', label='Training Time')\n",
    "lines_1.append(line2)\n",
    "labels_1.append('training time')\n",
    "ax2.set_ylabel('Training Time (s)')\n",
    "ax2.grid(False)\n",
    "\n",
    "\n",
    "desired_order = ['average', 'waiting time', 'travel time', 'time loss', 'waiting count', 'speed', 'training time']\n",
    "line_dict = {label: line for line, label in zip(lines_1, labels_1)}\n",
    "sorted_lines = [line_dict[label] for label in desired_order]\n",
    "sorted_labels = desired_order\n",
    "\n",
    "# Combine into one legend + adjust locatino\n",
    "legend = ax1.legend(sorted_lines, sorted_labels, loc='upper center', bbox_to_anchor=(0.5, 1))\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68324e6b-ded5-4b85-9466-14637b0d9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('sample_efficiency_log_scale.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3f277-4096-446e-9e6f-02489eaa9934",
   "metadata": {},
   "source": [
    "### Linear scale graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c5dc7-6a60-4392-8c4e-a072fd4e3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df_merged['sample number']\n",
    "y_metrics = ['average', 'waiting time', 'time loss', 'travel time', 'speed', 'waiting count']\n",
    "training_time = df_merged['training time']\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# left y-axis : performance measures\n",
    "lines_1 = []\n",
    "labels_1 = []\n",
    "\n",
    "for col in y_metrics:\n",
    "    line, = ax1.plot(x, df_merged[col], marker='o', label=col)\n",
    "    lines_1.append(line)\n",
    "    labels_1.append(col)\n",
    "\n",
    "ax1.set_xlabel('Sample Number (log scale)')\n",
    "ax1.set_ylabel('MAPE (%)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# right y-axis: training time\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(x, training_time, color='black', linestyle='--', marker='x', label='Training Time')\n",
    "lines_1.append(line2)\n",
    "labels_1.append('training time')\n",
    "ax2.set_ylabel('Training Time (s)')\n",
    "ax2.grid(False)\n",
    "\n",
    "\n",
    "desired_order = ['average', 'waiting time', 'travel time', 'time loss', 'waiting count', 'speed', 'training time']\n",
    "line_dict = {label: line for line, label in zip(lines_1, labels_1)}\n",
    "sorted_lines = [line_dict[label] for label in desired_order]\n",
    "sorted_labels = desired_order\n",
    "\n",
    "# Combine into one legend + adjust locatino\n",
    "legend = ax1.legend(sorted_lines, sorted_labels, loc='upper center', bbox_to_anchor=(0.3, 1))\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f81c8-3676-4ede-8edb-f10121b8bcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e14533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data_total.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da22feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycols = [\n",
    "    x+str(i) for i in range(5) for x in ['speed', 'stop', 'timeloss', 'travel', 'wait']\n",
    "]\n",
    "\n",
    "ycol = [\n",
    "    df.columns[df.columns.str.contains('wait')],\n",
    "    df.columns[df.columns.str.contains('timeloss')],\n",
    "    df.columns[df.columns.str.contains('travel')],\n",
    "    df.columns[df.columns.str.contains('speed')],\n",
    "    df.columns[df.columns.str.contains('stop')],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "varcols = [f'p{i}' for i in range(1, 5)]\n",
    "pcols = df.columns[df.columns.str.contains('_')]\n",
    "qcols = ['1', '1l', '1r', '1s', \n",
    "         '2', '2l', '2r', '2s', \n",
    "         '3', '3l', '3r', '3s',\n",
    "         '4', '4l', '4r', '4s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06367ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df[varcols]\n",
    "p = df[pcols]\n",
    "q = df[qcols]\n",
    "y = [\n",
    "    df[c].mean(1) for c in ycol\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791514d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_perc(x):\n",
    "    return x.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "def process_var(_var, max_len=200):\n",
    "    var = to_perc(_var)\n",
    "    var['total_len'] = _var.sum(1) / max_len\n",
    "    return var\n",
    "\n",
    "def process_p(p, n_arms=4, max_v=1000):\n",
    "    for i in range(1, n_arms+1):\n",
    "        cols = list(filter(lambda x: int(x[0]) == i, p.columns))\n",
    "        p[f'{i}_v'] = p[cols].sum(1) / max_v\n",
    "        p[cols] = to_perc(p[cols])\n",
    "    return p\n",
    "\n",
    "def process_q(q_, n_arms=4):\n",
    "    q = q_.copy()\n",
    "    for i in range(1, n_arms+1):\n",
    "        q[list(filter(lambda x: len(x) > 1, q.columns[q.columns.str.contains(str(i))]))]  =\\\n",
    "            q[list(filter(lambda x: len(x) > 1, q.columns[q.columns.str.contains(str(i))]))].apply(lambda x: x/q[str(i)])\n",
    "        q[str(i)] /= 7\n",
    "\n",
    "    q_ohe = [tf.squeeze(tf.one_hot(feat, 7), 0).numpy() for i, feat in enumerate(q_.values.reshape(-1, 1, 16).T-1)]\n",
    "    q_ohe = tf.concat(q_ohe, axis=1).numpy()\n",
    "    q_ohe = pd.DataFrame(q_ohe)\n",
    "    q = pd.concat([q, q_ohe], axis=1)\n",
    "    return q\n",
    "\n",
    "def preprocess_all(p, q, var):\n",
    "    p = process_p(p)\n",
    "    q = process_q(q)\n",
    "    var = process_var(var)\n",
    "    \n",
    "    return p, q, var\n",
    "    \n",
    "def postprocess_var(var):\n",
    "    m = var[4]*200\n",
    "    return [int(x*m) for x in var[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p, q, var = preprocess_all(p, q, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv('preprocessed/preprocessed_p.csv')\n",
    "q.to_csv('preprocessed/preprocessed_q.csv')\n",
    "var.to_csv('preprocessed/preprocessed_var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25049278",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a9363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

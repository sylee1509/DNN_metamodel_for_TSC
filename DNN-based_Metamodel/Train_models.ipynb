{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb66d71-83d6-47ce-a8f6-b2641636fe28",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fd537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1a375-6273-4551-ac1f-10f415da28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a70057",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'data/data_total.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feade057",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycols = [\n",
    "    x+str(i) for i in range(5) for x in ['speed', 'stop', 'timeloss', 'travel', 'wait']\n",
    "]\n",
    "\n",
    "ycol = [\n",
    "    df.columns[df.columns.str.contains('wait')],\n",
    "    df.columns[df.columns.str.contains('timeloss')],\n",
    "    df.columns[df.columns.str.contains('travel')],\n",
    "    df.columns[df.columns.str.contains('speed')],\n",
    "    df.columns[df.columns.str.contains('stop')],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\n",
    "    df[c].mean(1) for c in ycol\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07406a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv('preprocessed/preprocessed_p.csv', index_col=0)\n",
    "q = pd.read_csv('preprocessed/preprocessed_q.csv', index_col=0)\n",
    "var = pd.read_csv('preprocessed/preprocessed_var.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d932972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d561dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca133eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a255276",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41251d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([var, p, q], 1)\n",
    "X_wo_p = pd.concat([var, q], 1)\n",
    "X_wo_q = pd.concat([var, p], 1)\n",
    "X_wo_pq = pd.concat([var], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:,:3] /= 300\n",
    "y[:, 3] = (y[:, 3]-3)/6\n",
    "y[:, 4] /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97931860-a894-4013-a903-ad714b1242a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[:,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38b81e-6363-4948-a8f2-d8cc9a536ff2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a32c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_MLP_y1_model():\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    h = Dense(256, activation='swish')(i_)\n",
    "    h = Dense(128, activation='swish')(h)\n",
    "    h = Dense(64, activation='swish')(h)\n",
    "    o_ = Dense(1)(h)\n",
    "\n",
    "    return tf.keras.models.Model(i_, o_)\n",
    "\n",
    "\"\"\"\n",
    "# Gora, P., & Bardo≈Ñski, M. (2017, June). \n",
    "# Training neural networks to approximate traffic simulation outcomes. \n",
    "# In 2017 5th IEEE International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS) (pp. 889-894). IEEE.\n",
    "\"\"\"\n",
    "def get_Gora_and_Bardonski_model(dropout_rate=0.05):\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    h = Dense(100, activation='relu')(i_)\n",
    "    h = Dropout(dropout_rate)(h)\n",
    "    h = Dense(200, activation='relu')(h)\n",
    "    h = Dropout(dropout_rate)(h)\n",
    "    h = Dense(100, activation='relu')(h)\n",
    "    h = Dropout(dropout_rate)(h)\n",
    "    o_ = Dense(1)(h)\n",
    "\n",
    "    return tf.keras.models.Model(i_, o_)\n",
    "\n",
    "\n",
    "def get_simple_MLP_y5_model():\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    h = Dense(256, activation='swish')(i_)\n",
    "    h = Dense(128, activation='swish')(h)\n",
    "    h = Dense(64, activation='swish')(h)\n",
    "    o_ = Dense(5)(h)\n",
    "\n",
    "    return tf.keras.models.Model(i_, o_)\n",
    "\n",
    "\n",
    "def get_shared_bottom_model(num_tasks=5, emb_dim=64):\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    h = Dense(256, activation='swish')(i_)\n",
    "    h = Dense(128, activation='swish')(h)\n",
    "    shared_bottom_out = Dense(emb_dim, activation='swish')(h)\n",
    "\n",
    "    task_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(shared_bottom_out)\n",
    "        task_outs.append(out)\n",
    "    \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def get_MMoE_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X.shape[1]\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    mmoe_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "        g_in = g_layer(i_)\n",
    "        g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "        g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "        \n",
    "        g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "        \n",
    "        mmoe_outs.append(g_mul_out)\n",
    "        \n",
    "    task_outs = []\n",
    "    for mmoe_out in mmoe_outs:\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(mmoe_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def get_OMoE_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X.shape[1]\n",
    "    i_ = Input((X.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "    g_in = g_layer(i_)\n",
    "    g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "    g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "    \n",
    "    g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "    \n",
    "    task_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(g_mul_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def get_MMoE_wo_q_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X_wo_q.shape[1]\n",
    "    i_ = Input((X_wo_q.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    mmoe_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "        g_in = g_layer(i_)\n",
    "        g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "        g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "        \n",
    "        g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "        \n",
    "        mmoe_outs.append(g_mul_out)\n",
    "        \n",
    "    task_outs = []\n",
    "    for mmoe_out in mmoe_outs:\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(mmoe_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def get_MMoE_wo_p_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X_wo_p.shape[1]\n",
    "    i_ = Input((X_wo_p.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    mmoe_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "        g_in = g_layer(i_)\n",
    "        g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "        g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "        \n",
    "        g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "        \n",
    "        mmoe_outs.append(g_mul_out)\n",
    "        \n",
    "    task_outs = []\n",
    "    for mmoe_out in mmoe_outs:\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(mmoe_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def get_MMoE_wo_pq_model(num_experts=3, num_tasks=5, emb_dim=64):\n",
    "    in_dim = X_wo_pq.shape[1]\n",
    "    i_ = Input((X_wo_pq.shape[1], ))\n",
    "    \n",
    "    experts = []\n",
    "    for _ in range(num_experts):\n",
    "        exp = build_layer(in_dim, (256, 128), emb_dim)\n",
    "        experts.append(exp(i_))\n",
    "        \n",
    "    expert_concat = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(experts)\n",
    "    \n",
    "    mmoe_outs = []\n",
    "    for _ in range(num_tasks):\n",
    "        g_layer = build_layer(in_dim, (128, ), emb_dim)\n",
    "        g_in = g_layer(i_)\n",
    "        g_out = tf.keras.layers.Dense(num_experts, use_bias=False, activation='softmax')(g_in)\n",
    "        g_out = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(g_out)\n",
    "        \n",
    "        g_mul_out = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=False))([expert_concat, g_out])\n",
    "        \n",
    "        mmoe_outs.append(g_mul_out)\n",
    "        \n",
    "    task_outs = []\n",
    "    for mmoe_out in mmoe_outs:\n",
    "        out_layer = build_layer(emb_dim, (64, ), 1)\n",
    "        out = out_layer(mmoe_out)\n",
    "        task_outs.append(out)\n",
    "        \n",
    "    task_outs = tf.concat(task_outs, 1)\n",
    "    return tf.keras.models.Model(i_, task_outs)\n",
    "\n",
    "\n",
    "def build_layer(in_dim, h_dim, out_dim):\n",
    "    i_ = Input((in_dim, ))\n",
    "    h = i_\n",
    "    for d in h_dim:\n",
    "       h = Dense(d, activation='swish')(h)\n",
    "    \n",
    "    o = Dense(out_dim)(h)\n",
    "    model = tf.keras.models.Model(i_, o)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b91df6-eec0-451c-a440-c40b50e84caf",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/test_networks.csv', 'r', newline='') as myfile:\n",
    "     wr = csv.reader(myfile, quoting=csv.QUOTE_ALL)\n",
    "     test_data = list(wr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384c9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "val_id = list(tqdm(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de1d7b-2af8-4f45-bb49-e1edfea4f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = X[~strat.isin(val_id)]\n",
    "tr_X_wo_p = X_wo_p[~strat.isin(val_id)] \n",
    "tr_X_wo_q = X_wo_q[~strat.isin(val_id)] \n",
    "tr_X_wo_pq = X_wo_pq[~strat.isin(val_id)] \n",
    "tr_y = y[~strat.isin(val_id)]\n",
    "tr_y1 = y1[~strat.isin(val_id)]\n",
    "\n",
    "val_X = X[strat.isin(val_id)]\n",
    "val_X_wo_p = X_wo_p[strat.isin(val_id)]\n",
    "val_X_wo_q = X_wo_q[strat.isin(val_id)]\n",
    "val_X_wo_pq = X_wo_pq[strat.isin(val_id)]\n",
    "val_y = y[strat.isin(val_id)]\n",
    "val_y1 = y1[strat.isin(val_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84a9cf-0707-4c9d-ae64-12ad49f4fdd0",
   "metadata": {},
   "source": [
    "## Single-output Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c6da9-0cea-4816-bcbd-ef9871b77c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dbde1-278f-4ec5-9053-45695da559c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('transformer', PolynomialFeatures(degree=2, include_bias=False), ['p1', 'p2', 'p3', 'p4', 'total_len']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "tr_X_poly = poly.fit_transform(tr_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520cfc24-b605-4d02-8855-f0f84bc11389",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "lin_reg.fit(tr_X_poly, tr_y1)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67099c93-6d61-4df5-a949-7e1b9c661551",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_poly_reg/model.pkl','wb') as f:\n",
    "    pickle.dump(lin_reg,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1de3a-7722-4101-b134-272c74cc4461",
   "metadata": {},
   "source": [
    "## Single-output MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b577e7b-c0d1-411c-ad94-4c504649ea4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_simple_MLP_y1_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y1,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb6a03-ef8b-48e9-b442-1074ce906638",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_simple_MLP_y1\")\n",
    "\n",
    "with open('model_simple_MLP_y1/historyDict', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c1a362-dfb5-4369-a69c-7cd9523d8bef",
   "metadata": {},
   "source": [
    "## Single-output MLP (Pawel Gora and Marek Bardonski, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb3090-1b9f-4ec8-af98-bf2bc1c57887",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=1000, restore_best_weights=True)\n",
    "\n",
    "model = get_Gora_and_Bardonski_model(dropout_rate=0.05)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y1,\n",
    "         epochs=1000000,\n",
    "         batch_size=10240,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbec275-4d16-40be-a83d-ad5934d4f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_Gora_and_Bardonski\")\n",
    "\n",
    "with open('model_Gora_and_Bardonski/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76599697-c42d-443e-9548-89b269a0fb23",
   "metadata": {},
   "source": [
    "## Multi-output MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f161e37-9d64-48fb-82aa-202b9a9e8858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_simple_MLP_y5_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30115b0-a3b4-414a-8cae-d1228a0ffe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_simple_MLP_y5\")\n",
    "\n",
    "with open('model_simple_MLP_y5/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946c5d3-1aec-4e4b-86d0-81fdeca850de",
   "metadata": {},
   "source": [
    "## Multi-output Shared Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e5c75-8722-4ca8-8d53-8a88de4483ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_shared_bottom_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f1e8f-64d2-449d-95b0-ab9854ae1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_shared_bottom\")\n",
    "\n",
    "with open('model_shared_bottom/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06ef16-8881-4b05-bcd6-9d5c91ec645d",
   "metadata": {},
   "source": [
    "## Multi-output OMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8f54c-a9fa-4303-81f3-e652ea9890ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_OMoE_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61908215-c93f-4110-8bbf-e1f5c8d9fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_OMoE\")\n",
    "\n",
    "with open('model_OMoE/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8890b18-9bea-4781-81b1-80d5276907e6",
   "metadata": {},
   "source": [
    "## Multi-output MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d75a9e-e7d1-4291-8e26-92cfd9d2f091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_MMoE_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b36a02-86e0-4882-8089-c67fbf2bc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_MMoE_original\")\n",
    "\n",
    "with open('model_MMoE_original/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cdf02-5568-4931-8b63-e9b95d8a6530",
   "metadata": {},
   "source": [
    "## Multi-output MMoE without traffic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5858f129-2221-40a8-9931-51c1d18764e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_MMoE_wo_p_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X_wo_p, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_MMoE_wo_traffic_param\")\n",
    "\n",
    "with open('model_MMoE_wo_traffic_param/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8609f-7a5a-403a-94d9-214c6461ee95",
   "metadata": {},
   "source": [
    "## Multi-output MMoE without network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e1a2f-fa3e-469a-a5ed-16982fa3c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_MMoE_wo_q_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X_wo_q, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb1c2c-e6f9-455f-ad05-7d785a1f979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_MMoE_wo_network_param\")\n",
    "\n",
    "with open('model_MMoE_wo_network_param/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670f31b-94ce-4754-a495-d61db55f9a24",
   "metadata": {},
   "source": [
    "## Multi-output MMoE without both parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3731c2f-ab07-44b2-9df2-343df6c65174",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "ld = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, min_lr=5e-5)\n",
    "\n",
    "model = get_MMoE_wo_pq_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.compile(loss='mape', optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = model.fit(tr_X_wo_pq, tr_y,\n",
    "         epochs=1500,\n",
    "         batch_size=1024,\n",
    "         validation_split=0.15,\n",
    "         callbacks=[es, ld],\n",
    "         shuffle=True,\n",
    "         )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Elapsed time is {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77046244-c008-437d-93b4-6436943e52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_MMoE_wo_both_param\")\n",
    "\n",
    "with open('model_MMoE_wo_both_param/historyDict', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131aa229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
